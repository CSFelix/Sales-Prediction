{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 align=\"center\">üõçÔ∏è US Stores Sales üõçÔ∏è</h1>\n\n<center><i>US Stores Sales Between 2010 and 2011<i></center>\n    \n**Dataset: [US Stores Sales](https://www.kaggle.com/datasets/dsfelix/us-stores-sales)**","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"----\n\n<h1>üìù Description</h1>\n\n<p>You're provided with daily historical sales data between January 1th in 2010 and December 31th in 2011. The task is to forecast the Total Value of Sales in Dollars given some info about the Stores, Products and Accountability.</p>\n\n<p>Try on applying different Machine and Deep Learning Models. Good Luck!! üçÄüçÄ</p>","metadata":{}},{"cell_type":"markdown","source":"----\n\n<h1>üìÅ File Descriptions</h1>\n\n<br/>\n\n> **sales.csv** - the training and testing set. Daily historical data from January 2010 to December 2011 (one of this challenge goals is to split up the dataset into training and testing set).","metadata":{}},{"cell_type":"markdown","source":"----\n\n<h1>‚ùì Variables</h1>\n\n<br/>\n\n> **Area Code** - Store's Code;\n\n> **State** - Store's State;\n\n> **Market** - Store's Region;\n\n> **Market Size** - Store's Size;\n\n> **Profit** - Profits in Dollars;\n\n> **Margin** - Profit + Total Expenses OR Sales - COGS;\n\n> **üåü Sales üåü** - Values Acquired in Sales (this is your target);\n\n> **COGS** - Cost of Goods Sold;\n\n> **Total Expenses** - Total Expenses to get the Product to Sell;\n\n> **Marketing** - Expenses in Marketing;\n\n> **Inventory** - Inventory Value of the Product in the Sale Moment;\n\n> **Budget Profit** - Expected Profit;\n\n> **Budget COGS** - Expected COGS;\n\n> **Budget Margin** - Expected Profit + Expected Total Expenses OR Expected Sales - Expected COGS;\n\n> **Budget Sales** - Expected Value Acquired in Sales;\n\n> **ProductID** - Product ID;\n\n> **Date** - Sale Date;\n\n> **Product Type** - Product Category;\n\n> **Product** - Product Description;\n\n> **Type** - Type.","metadata":{}},{"cell_type":"markdown","source":"----\n\n<h1>üéØ Goals</h1>\n\n<br/>\n\n> **Goal 1:** predict the Total Acquired Value on Sales in Dollars;\n\n> **Goal 2:** get a score lower than 15 dollars (RMSE);\n\n> **Bonus Goal:** apply XGBoost;\n\n<br/>\n\n----","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nnp.random.seed(2004)\nsns.set_style('whitegrid')","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:09.788249Z","iopub.execute_input":"2022-11-12T20:01:09.788621Z","iopub.status.idle":"2022-11-12T20:01:09.794166Z","shell.execute_reply.started":"2022-11-12T20:01:09.788583Z","shell.execute_reply":"2022-11-12T20:01:09.793167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_sales = pd.read_csv('../input/us-stores-sales/sales.csv')\nfull_sales.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:16.805646Z","iopub.execute_input":"2022-11-12T20:01:16.806415Z","iopub.status.idle":"2022-11-12T20:01:16.864984Z","shell.execute_reply.started":"2022-11-12T20:01:16.806380Z","shell.execute_reply":"2022-11-12T20:01:16.864013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As far the 'ProductId' Feature indicates each product\n# there's no need to maintain 'Product' Feature\n#\n# Also, as far as 'Profit' and 'Margin' Featurees are 'Future Features',\n# that is, their values are calculated with our target ('Sales') already known,\n# we gotta drop them too in order to avoid Target Leakage\nfeatures_to_drop = ['Product', 'Profit', 'Margin']\nsales = full_sales.drop(features_to_drop, axis=1).copy()\nsales.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:17.314670Z","iopub.execute_input":"2022-11-12T20:01:17.315074Z","iopub.status.idle":"2022-11-12T20:01:17.338424Z","shell.execute_reply.started":"2022-11-12T20:01:17.315039Z","shell.execute_reply":"2022-11-12T20:01:17.337377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----\n\n<h1>üîç Exploratory Analysis</h1>\n\nIn the Exploratory Analysis, let's check out the variables' data types, see their distributions and correlations and plot some charts with seaborn!","metadata":{}},{"cell_type":"markdown","source":"<b>Data Types</b>","metadata":{}},{"cell_type":"code","source":"sales.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:18.791456Z","iopub.execute_input":"2022-11-12T20:01:18.791809Z","iopub.status.idle":"2022-11-12T20:01:18.799254Z","shell.execute_reply.started":"2022-11-12T20:01:18.791778Z","shell.execute_reply":"2022-11-12T20:01:18.798146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well, it seems that almost all features are in its proper data type, but **Date**, which is *object* instead of *date*.\n\nIn the moment, all Date Values are in the format **DD/MM/YY HH:mm:ss**, so let's transform them into **DD/MM/YY**.","metadata":{}},{"cell_type":"code","source":"import datetime\n\n# Getting just the date part of 'Date' Feature in DD/MM/YY format\n# and converting the string into datetime\nsales['Date'] = sales['Date'].apply(lambda row:row[0:8])\nsales['Date'] = pd.to_datetime(sales['Date'], format='%d/%m/%y')\nsales['Date'].head()","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:19.621710Z","iopub.execute_input":"2022-11-12T20:01:19.622113Z","iopub.status.idle":"2022-11-12T20:01:19.637695Z","shell.execute_reply.started":"2022-11-12T20:01:19.622073Z","shell.execute_reply":"2022-11-12T20:01:19.636803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:19.944308Z","iopub.execute_input":"2022-11-12T20:01:19.944962Z","iopub.status.idle":"2022-11-12T20:01:19.951975Z","shell.execute_reply.started":"2022-11-12T20:01:19.944927Z","shell.execute_reply":"2022-11-12T20:01:19.951234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üéâüéâ Niceee!! We have converted the **Date** Feature to **Datetime64[ns]** datatype successfully!!\n\nNow, let's move forward to some Statistical Overview!!","metadata":{}},{"cell_type":"markdown","source":"----\n\n<b>Statistical Overview</b>\n\nIn order to analyse the dataset better, let's split up the statistical overview in two: *Numbers Stats* and *Categorical Stats*.","metadata":{}},{"cell_type":"code","source":"# Number Stats\nsales.describe()","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:22.771211Z","iopub.execute_input":"2022-11-12T20:01:22.771594Z","iopub.status.idle":"2022-11-12T20:01:22.812038Z","shell.execute_reply.started":"2022-11-12T20:01:22.771555Z","shell.execute_reply":"2022-11-12T20:01:22.811156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the stats, we can realize:\n\n> **Inventory** minimum values are negative: it's not possible to happen, because at the moment the inventory is equals zero, the market doesn't have the product phisically to sell. So, let's make a small Data Transformation to convert all negative Invetories to zero;\n\n> **High Standard Deviation**: take a look at *75%* and *max* stats from **Sales** Feature, the difference between these two is *930.00 dollars*, quite a big gap! Due to this the Standard Deviation is very high (*148,.89 dollars*), so, it'll be a problem in the  future if we don't take an action to fix it;\n\n> **Data Standardization**: the maximum value of **Product ID** Feature is *13*, whereas the minimum value of **Area** one is *203.00*. Then, in order to don't make the ML Model learn that Area is more important than the Product ID just because its values are higher, we will have to apply Data Standardization during the Pipelines Step.  With this, we will solve this problem and the **High Standard Deviation** together. Two birds with one stone!! üê¶üê¶ü•å\n\nFor now, let's focus to convert all negative inventories to zero.","metadata":{}},{"cell_type":"code","source":"# Converting all negative values of inventory to zero\nsales['Inventory'] = sales['Inventory'].apply(lambda x: x if x >= 0 else 0)\nsales.describe()","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:32.727791Z","iopub.execute_input":"2022-11-12T20:01:32.728193Z","iopub.status.idle":"2022-11-12T20:01:32.771736Z","shell.execute_reply.started":"2022-11-12T20:01:32.728158Z","shell.execute_reply":"2022-11-12T20:01:32.770818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All right, now the minimum value of **Inventory** is zero.\n\nLet's take a peep on the Categorical Features' Stats!!","metadata":{}},{"cell_type":"code","source":"# Categorical Stats\nsales.describe(include=['object'])","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:33.989521Z","iopub.execute_input":"2022-11-12T20:01:33.989949Z","iopub.status.idle":"2022-11-12T20:01:34.012940Z","shell.execute_reply.started":"2022-11-12T20:01:33.989912Z","shell.execute_reply":"2022-11-12T20:01:34.012145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hmm, it seems okay!! Just realize:\n\n> There are **four Markets** distributed into **twenty States**;\n\n> Also, we are working with two Market Sizes: **Small** and **Big**;\n\n<br>\n\n‚ùì Now, there's a question: is there any Linear Relationship between the numerical values? Let's find it out!!","metadata":{}},{"cell_type":"markdown","source":"----\n\n<b>Correlations</b>","metadata":{}},{"cell_type":"code","source":"sales.corr()","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:35.303161Z","iopub.execute_input":"2022-11-12T20:01:35.303533Z","iopub.status.idle":"2022-11-12T20:01:35.324361Z","shell.execute_reply.started":"2022-11-12T20:01:35.303502Z","shell.execute_reply":"2022-11-12T20:01:35.323249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well, we have a bunch of Linear Relationships (LN) here (it's quite obvious, if you read the dataset desciption, you'll realize that most of the features were calculated using simple linear math equations, so, it would be kind of weird if the dataset doesn't have any Linear Relationships üòÇüòÇ).\n\nBetween all of LR, let's go deep in these three:\n\n> **Marketing - Inventory (53.41%)**: as more marketing the market does for a specific as higher will be the Product Inventtory. One of the reasons here is due to the belief that more clients will be interested to buy the shared products and then, the market will more units of the products to sell;\n\n> **Total Expenses - Marketing (96.66%)**: as higher is Total Expenses as higher is the costs in Marketing. It means that markets with more costs gain more money and, consequently, can apply more money in the Marketing;\n\n<br>\n\nLet's plot these relationships!!","metadata":{}},{"cell_type":"code","source":"# Marketing - Inventory (Linear Coefficient: 53.41%)\n\nplt.figure(figsize=(15,7))\nplt.title('Costs Marketing x Inventory')\n\nsns.regplot(data=sales, x='Marketing', y='Inventory')\n\nplt.xlabel('Marketing (U$)')\nplt.ylabel('Inventory')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:36.055206Z","iopub.execute_input":"2022-11-12T20:01:36.055731Z","iopub.status.idle":"2022-11-12T20:01:36.652019Z","shell.execute_reply.started":"2022-11-12T20:01:36.055700Z","shell.execute_reply":"2022-11-12T20:01:36.651069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total Expenses - Marketing (Linear Coefficient: 96.66%)\n\nplt.figure(figsize=(15,7))\nplt.title('Total Expenses x Costs Marketing')\n\nsns.regplot(data=sales, x='Total Expenses', y='Marketing')\n\nplt.xlabel('Total Expenses (U$)')\nplt.ylabel('Marketing (U$)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:36.653828Z","iopub.execute_input":"2022-11-12T20:01:36.654430Z","iopub.status.idle":"2022-11-12T20:01:37.234045Z","shell.execute_reply.started":"2022-11-12T20:01:36.654376Z","shell.execute_reply":"2022-11-12T20:01:37.233156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----\n\nOkay, now, let's see if any oof Number Features have a Normal Distribution.","metadata":{}},{"cell_type":"code","source":"# As far some features don't have a Linear Relationship\n# at the moment, let's see how the datas are spread\nsales.hist(bins=15, figsize=(15, 10));","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:37.241163Z","iopub.execute_input":"2022-11-12T20:01:37.241657Z","iopub.status.idle":"2022-11-12T20:01:39.322995Z","shell.execute_reply.started":"2022-11-12T20:01:37.241629Z","shell.execute_reply":"2022-11-12T20:01:39.322326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Woow, we have such interesting histograms here:\n\n> **Budget Profit and Budget Margin** have Normal Distribution;\n\n> **Sales, COGS, Total Expenses, Marketing and Budget Sales** have Tail Distribution too Right;\n\n> **Date** has values bettween 15 days in 2010 and 15 days in 2011 (the histogram has been plotted with each bar representing an interval of 15 possible values).\n\n----\n\nNow, to finish this section, let's create a new Feature called **Budget Total Expenses**, using the following equation:\n\n```\n                $Budget Total Expenses = Budget Margin - Budget Profit$\n```","metadata":{}},{"cell_type":"code","source":"# Creating 'Budget Total Expenses' Feature\nsales.insert(loc=12, column='Budget Total Expenses', value=sales['Budget Margin'] - sales['Budget Profit'])\nsales.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:39.324612Z","iopub.execute_input":"2022-11-12T20:01:39.324897Z","iopub.status.idle":"2022-11-12T20:01:39.347103Z","shell.execute_reply.started":"2022-11-12T20:01:39.324871Z","shell.execute_reply":"2022-11-12T20:01:39.346351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----\n\n<b>Categorical Features Data Entry</b>\n\nNoow, let's coonvert all Categorical Features into lower case and check out if any of them has any inconsistent datas.","metadata":{}},{"cell_type":"code","source":"# Convertiing all Categorical Features into lower case\nsales['State']          =  sales['State'].str.lower()\nsales['Market']         =  sales['Market'].str.lower()\nsales['Market Size']    =  sales['Market Size'].str.lower()\nsales['Product Type']   =  sales['Product Type'].str.lower()\nsales['Type']           =  sales['Type'].str.lower()\n\nsales.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:41.633258Z","iopub.execute_input":"2022-11-12T20:01:41.633720Z","iopub.status.idle":"2022-11-12T20:01:41.666525Z","shell.execute_reply.started":"2022-11-12T20:01:41.633687Z","shell.execute_reply":"2022-11-12T20:01:41.665724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, let's check out each unique value from the Categorical Features in order to check out\n# for any inconsistent datas\nprint('States:',        sales['State'].unique(),         '\\n')\nprint('Market:',        sales['Market'].unique(),        '\\n')\nprint('Market Size:',   sales['Market Size'].unique(),   '\\n')\nprint('Product Type:',  sales['Product Type'].unique(),  '\\n')\nprint('Type:',          sales['Type'].unique(),          '\\n')","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:41.667790Z","iopub.execute_input":"2022-11-12T20:01:41.668149Z","iopub.status.idle":"2022-11-12T20:01:41.676129Z","shell.execute_reply.started":"2022-11-12T20:01:41.668124Z","shell.execute_reply":"2022-11-12T20:01:41.675208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üéâüéâ Hoorray!! There are not duplicated and inconsistent categorical values, so let's move on to split the dataset into Train and Test!!","metadata":{}},{"cell_type":"markdown","source":"----\n\n<h1>üì¶ Splitting Dataset into Features and Target</h1>\n\nAs far as we gotta predict **Sales**, let's separate this Feature to be our Target!!","metadata":{}},{"cell_type":"code","source":"X = sales.copy()\ny = X.pop('Sales')","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:44.081002Z","iopub.execute_input":"2022-11-12T20:01:44.082084Z","iopub.status.idle":"2022-11-12T20:01:44.089100Z","shell.execute_reply.started":"2022-11-12T20:01:44.082040Z","shell.execute_reply":"2022-11-12T20:01:44.088101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----\n\n<h1>‚öôÔ∏è Feature Engineering</h1>\n\nBefore starting creating a ML Model, let's make some Data Engineering and Analysis.\n\nKicking off from Engineering, we will:\n\n> check out which number features are most important with **Mutual Information (MI)**;\n\n> try to find out similar datas in groups using **K-Means Clusters**.\n\nC'mon, we're almost there,just a few steps to kick off our model building!!","metadata":{}},{"cell_type":"markdown","source":"----\n\n<b>Mutual Information (MI)</b>","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_regression","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:45.542863Z","iopub.execute_input":"2022-11-12T20:01:45.543324Z","iopub.status.idle":"2022-11-12T20:01:45.548406Z","shell.execute_reply.started":"2022-11-12T20:01:45.543289Z","shell.execute_reply":"2022-11-12T20:01:45.547251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the Discrete and Continuous Features' Names\nX_discrete_features = [col for col in X.columns\n                      if X[col].dtype == 'int64']\nX_continuous_features = [col for col in X.columns\n                        if X[col].dtype =='float64']\n\n# Identifying which number features are discrete and which ones are continuous\ndiscrete_features = X[X_discrete_features].dtypes == int\ncontinuous_features = X[X_continuous_features].dtypes == float","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:46.343668Z","iopub.execute_input":"2022-11-12T20:01:46.344224Z","iopub.status.idle":"2022-11-12T20:01:46.353224Z","shell.execute_reply.started":"2022-11-12T20:01:46.344190Z","shell.execute_reply":"2022-11-12T20:01:46.352083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to Plot MI Scores\ndef plot_mi_scores(scores):\n    \"\"\"\n    Plots Mutual Information Scores in Ascending Order\n    \"\"\"\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:46.803964Z","iopub.execute_input":"2022-11-12T20:01:46.805127Z","iopub.status.idle":"2022-11-12T20:01:46.811192Z","shell.execute_reply.started":"2022-11-12T20:01:46.805082Z","shell.execute_reply":"2022-11-12T20:01:46.810109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating and Plotting Discrete Features MI Scores\nmi_scores_discrete_features = mutual_info_regression(X[X_discrete_features], y, discrete_features=discrete_features, random_state=2004)\nmi_scores_discrete_features = pd.Series(mi_scores_discrete_features, name='MI Scores 1', index=X_discrete_features)\nmi_scores_discrete_features = mi_scores_discrete_features.sort_values(ascending=False)\n\nplt.figure(dpi=100, figsize=(8,5))\nplot_mi_scores(mi_scores_discrete_features)","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:47.257123Z","iopub.execute_input":"2022-11-12T20:01:47.257754Z","iopub.status.idle":"2022-11-12T20:01:47.642811Z","shell.execute_reply.started":"2022-11-12T20:01:47.257709Z","shell.execute_reply":"2022-11-12T20:01:47.641878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay, looking at the plot, we can assume that **Area Code** has more influence to increase the Market Sells than **ProductId**.","metadata":{}},{"cell_type":"code","source":"# Calculating and Plotting Continuous Features MI Scores\nmi_scores_continuous_features = mutual_info_regression(X[X_continuous_features], y, discrete_features=continuous_features, random_state=2004)\nmi_scores_continuous_features = pd.Series(mi_scores_continuous_features, name='MI Scores 1', index=X_continuous_features)\nmi_scores_continuous_features = mi_scores_continuous_features.sort_values(ascending=False)\n\nplt.figure(dpi=100, figsize=(8,5))\nplot_mi_scores(mi_scores_continuous_features)","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:48.075545Z","iopub.execute_input":"2022-11-12T20:01:48.075938Z","iopub.status.idle":"2022-11-12T20:01:49.310216Z","shell.execute_reply.started":"2022-11-12T20:01:48.075902Z","shell.execute_reply":"2022-11-12T20:01:49.309161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And, about the continuous features, **Inventory**, **COGS** and **Marketing** are the *most influencer features*.","metadata":{}},{"cell_type":"markdown","source":"----\n\n<b>K-Means Cluster</b>","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:49.311679Z","iopub.execute_input":"2022-11-12T20:01:49.312105Z","iopub.status.idle":"2022-11-12T20:01:49.316096Z","shell.execute_reply.started":"2022-11-12T20:01:49.312076Z","shell.execute_reply":"2022-11-12T20:01:49.315395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First, let's find ouot what's the perfect number of clusters applying\n# the Elbow and WCSS Methods\n\nnumber_features = [col for col in X.columns\n                    if X[col].dtype in ['int64', 'float64']]\n\nwcss = []\n\nfor i in range(1,7):\n    kmeans = KMeans(n_clusters=i\n                   , init='k-means++'\n                   , max_iter=300\n                   , n_init=10\n                   , random_state=2004)\n    kmeans.fit(X[number_features])\n    wcss.append(kmeans.inertia_)","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:49.575071Z","iopub.execute_input":"2022-11-12T20:01:49.576087Z","iopub.status.idle":"2022-11-12T20:01:57.340981Z","shell.execute_reply.started":"2022-11-12T20:01:49.576029Z","shell.execute_reply":"2022-11-12T20:01:57.340058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the results\nplt.plot(range(1,7), wcss)\nplt.title('Elbow Method')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:57.342514Z","iopub.execute_input":"2022-11-12T20:01:57.343420Z","iopub.status.idle":"2022-11-12T20:01:57.568602Z","shell.execute_reply.started":"2022-11-12T20:01:57.343385Z","shell.execute_reply":"2022-11-12T20:01:57.567681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have three elbows here: **2, 3 and 4 clusters**. Let's use **4 clusters** in our analysis.","metadata":{}},{"cell_type":"code","source":"# Calculating K-Means with 4 clusters\nkmeans = KMeans(n_clusters=4\n                   , init='k-means++'\n                   , max_iter=300\n                   , n_init=10\n                   , random_state=2004)\n\nX_temp = X.copy()\nX_temp.insert(loc=0, column='Cluster', value=kmeans.fit_predict(X_temp[number_features]))\nX_temp","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:57.569765Z","iopub.execute_input":"2022-11-12T20:01:57.570052Z","iopub.status.idle":"2022-11-12T20:01:58.901333Z","shell.execute_reply.started":"2022-11-12T20:01:57.570027Z","shell.execute_reply":"2022-11-12T20:01:58.900350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking out if the Cluster followed the ProductId pattern\nsns.relplot(\n    x='ProductId', y='Area Code', hue='Cluster', data=X_temp, height=6, palette='colorblind'\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:01:58.903179Z","iopub.execute_input":"2022-11-12T20:01:58.903477Z","iopub.status.idle":"2022-11-12T20:01:59.699972Z","shell.execute_reply.started":"2022-11-12T20:01:58.903450Z","shell.execute_reply":"2022-11-12T20:01:59.698999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As far as Cluster didn't follow Product Id pattern, let's add this new Feature into the main dataset (to understand what I'm talking about, check out this notebook [üõçÔ∏è Predicting Future Sales üõçÔ∏è](https://www.kaggle.com/code/dsfelix/predicting-future-sales) and give a read on **K-Means Cluster** section).","metadata":{}},{"cell_type":"code","source":"# Adding Cluster Feature into the main dataset, deleting X_temp in the memory\n# and seeing the result\nX.insert(loc=0, column='Cluster', value=X_temp['Cluster'])\n\ndel X_temp\n\nX.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:44.995667Z","iopub.execute_input":"2022-11-12T20:02:44.996047Z","iopub.status.idle":"2022-11-12T20:02:45.019327Z","shell.execute_reply.started":"2022-11-12T20:02:44.996012Z","shell.execute_reply":"2022-11-12T20:02:45.018203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----\n\n<h1>üß∫ Pipelines and Data Transformations</h1>\n\nFirst things first, let's kicking off looking for missing values.","metadata":{"execution":{"iopub.status.busy":"2022-11-11T00:43:10.511843Z","iopub.execute_input":"2022-11-11T00:43:10.512337Z","iopub.status.idle":"2022-11-11T00:43:10.520513Z","shell.execute_reply.started":"2022-11-11T00:43:10.512300Z","shell.execute_reply":"2022-11-11T00:43:10.519252Z"}}},{"cell_type":"code","source":"X.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:45.469220Z","iopub.execute_input":"2022-11-12T20:02:45.469613Z","iopub.status.idle":"2022-11-12T20:02:45.481163Z","shell.execute_reply.started":"2022-11-12T20:02:45.469580Z","shell.execute_reply":"2022-11-12T20:02:45.479973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![OMG](https://steamuserimages-a.akamaihd.net/ugc/273974515706513039/441EA3D383846BA5EDCD6710B650ECD7704E6077/?interpolation=lanczos-none&output-format=jpeg&output-quality=95&fit=inside%7C637%3A358&composite-to=*,*%7C637%3A358&background-color=black)\n\nOh My Gooood! There is a single missing value, ooh yeah!! So our unique steps to Pipelines is the Standardization for the Number Features and One-Hot Encoding for the Categorical One.\n\nNow, let's split the dataset into train and validation and search for any bad labels.","metadata":{}},{"cell_type":"code","source":"# Splitting datas \nfrom sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=2004\n                                                    , train_size=0.70\n                                                    , test_size=0.30)","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:51.813640Z","iopub.execute_input":"2022-11-12T20:02:51.814012Z","iopub.status.idle":"2022-11-12T20:02:51.823664Z","shell.execute_reply.started":"2022-11-12T20:02:51.813979Z","shell.execute_reply":"2022-11-12T20:02:51.822549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Searching for any bad labels\n\ncat_ord_features = [col for col in X_train.columns\n                  if X_train[col].dtype == 'object']\n\ngood_labels_ord_features = [col for col in cat_ord_features\n                          if set(X_valid[col]).issubset(set(X_train[col]))]\n\nbad_labels_ord_features = list(set(cat_ord_features) - set(good_labels_ord_features))\n\nprint('Good Labels:', good_labels_ord_features, '\\n')\nprint('Bad Labels:',  bad_labels_ord_features,  '\\n')","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:52.175356Z","iopub.execute_input":"2022-11-12T20:02:52.175883Z","iopub.status.idle":"2022-11-12T20:02:52.187590Z","shell.execute_reply.started":"2022-11-12T20:02:52.175853Z","shell.execute_reply":"2022-11-12T20:02:52.186556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![OMG](https://steamuserimages-a.akamaihd.net/ugc/273974515706513039/441EA3D383846BA5EDCD6710B650ECD7704E6077/?interpolation=lanczos-none&output-format=jpeg&output-quality=95&fit=inside%7C637%3A358&composite-to=*,*%7C637%3A358&background-color=black)\n\nDouble OMG!! No Bad Labels here!! Now iot's time to create Pipelines!!\n\n----","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.compose import ColumnTransformer","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:52.942335Z","iopub.execute_input":"2022-11-12T20:02:52.943017Z","iopub.status.idle":"2022-11-12T20:02:52.949262Z","shell.execute_reply.started":"2022-11-12T20:02:52.942974Z","shell.execute_reply":"2022-11-12T20:02:52.948355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating Numerical Transformer\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', RobustScaler())\n])","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:53.256423Z","iopub.execute_input":"2022-11-12T20:02:53.256806Z","iopub.status.idle":"2022-11-12T20:02:53.261849Z","shell.execute_reply.started":"2022-11-12T20:02:53.256770Z","shell.execute_reply":"2022-11-12T20:02:53.260847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating Categorical Transformer\ncategorical_transformer = Pipeline(steps=[\n    ('encoder', OrdinalEncoder()),\n    ('scaler', MinMaxScaler())\n])","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:53.532680Z","iopub.execute_input":"2022-11-12T20:02:53.533418Z","iopub.status.idle":"2022-11-12T20:02:53.538988Z","shell.execute_reply.started":"2022-11-12T20:02:53.533373Z","shell.execute_reply":"2022-11-12T20:02:53.538000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bundling Preprocessors\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('numerical', numerical_transformer, number_features),\n        ('categorical', categorical_transformer, good_labels_ord_features)\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:53.804230Z","iopub.execute_input":"2022-11-12T20:02:53.804601Z","iopub.status.idle":"2022-11-12T20:02:53.809970Z","shell.execute_reply.started":"2022-11-12T20:02:53.804570Z","shell.execute_reply":"2022-11-12T20:02:53.808919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----\n\n<h1>ü§ñ Baseline ML Models</h1>\n\nLet's create three baseline models:\n\n> **Linear Regressor**;\n\n> **Random Forest Regressor**;\n\n> **XGBoost**.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error # add 'np.sqrt()' to calculate RMSE\nimport statsmodels.api as sm","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:04:23.697184Z","iopub.execute_input":"2022-11-12T20:04:23.697567Z","iopub.status.idle":"2022-11-12T20:04:24.178515Z","shell.execute_reply.started":"2022-11-12T20:04:23.697538Z","shell.execute_reply":"2022-11-12T20:04:24.177411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to calculate RMSE\nrmse = lambda predictions, real_values: np.sqrt(mean_squared_error(predictions, real_values))","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:54.653814Z","iopub.execute_input":"2022-11-12T20:02:54.654161Z","iopub.status.idle":"2022-11-12T20:02:54.658930Z","shell.execute_reply.started":"2022-11-12T20:02:54.654132Z","shell.execute_reply":"2022-11-12T20:02:54.657905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----\n\n<b>Linear Regressor</b>","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:55.191982Z","iopub.execute_input":"2022-11-12T20:02:55.192528Z","iopub.status.idle":"2022-11-12T20:02:55.196674Z","shell.execute_reply.started":"2022-11-12T20:02:55.192497Z","shell.execute_reply":"2022-11-12T20:02:55.195892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating Model\nlinear_model = LinearRegression(\n    n_jobs=4\n)\n\nlinear_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', linear_model)\n])","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:55.433990Z","iopub.execute_input":"2022-11-12T20:02:55.434331Z","iopub.status.idle":"2022-11-12T20:02:55.438816Z","shell.execute_reply.started":"2022-11-12T20:02:55.434304Z","shell.execute_reply":"2022-11-12T20:02:55.438117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the Model and Making Predictions\nlinear_pipeline.fit(X_train, y_train)\nprint('Training Done!')\nlinear_predictions = linear_pipeline.predict(X_valid)\nprint('Predictions Done!')","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:55.704785Z","iopub.execute_input":"2022-11-12T20:02:55.705563Z","iopub.status.idle":"2022-11-12T20:02:55.763015Z","shell.execute_reply.started":"2022-11-12T20:02:55.705528Z","shell.execute_reply":"2022-11-12T20:02:55.761065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RMSE\nlinear_rmse = rmse(linear_predictions, y_valid)\nprint('Linear Regression RMSE: ', linear_rmse)","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:55.963854Z","iopub.execute_input":"2022-11-12T20:02:55.964421Z","iopub.status.idle":"2022-11-12T20:02:55.970241Z","shell.execute_reply.started":"2022-11-12T20:02:55.964391Z","shell.execute_reply":"2022-11-12T20:02:55.969282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and Validation Scores\nprint('Train Score: %.2f%%' % (linear_pipeline.score(X_train, y_train) * 100))\nprint('Validation Score: %.2f%%' % (linear_pipeline.score(X_valid, y_valid) * 100))","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:56.237698Z","iopub.execute_input":"2022-11-12T20:02:56.238066Z","iopub.status.idle":"2022-11-12T20:02:56.271346Z","shell.execute_reply.started":"2022-11-12T20:02:56.238031Z","shell.execute_reply":"2022-11-12T20:02:56.270080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Summary\nmodel = sm.OLS(y, sm.add_constant(X['ProductId'])).fit()\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:08:18.991703Z","iopub.execute_input":"2022-11-12T20:08:18.992081Z","iopub.status.idle":"2022-11-12T20:08:19.009273Z","shell.execute_reply.started":"2022-11-12T20:08:18.992047Z","shell.execute_reply":"2022-11-12T20:08:19.008100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----\n\n<b>Random Forest Regressor</b>","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:56.862892Z","iopub.execute_input":"2022-11-12T20:02:56.863305Z","iopub.status.idle":"2022-11-12T20:02:56.868048Z","shell.execute_reply.started":"2022-11-12T20:02:56.863271Z","shell.execute_reply":"2022-11-12T20:02:56.867098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating Model\nrfg_model = RandomForestRegressor(\n    n_estimators=250,\n    criterion='squared_error',\n    random_state=2004,\n)\n\nrfg_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', rfg_model)\n])","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:57.174582Z","iopub.execute_input":"2022-11-12T20:02:57.175214Z","iopub.status.idle":"2022-11-12T20:02:57.181077Z","shell.execute_reply.started":"2022-11-12T20:02:57.175179Z","shell.execute_reply":"2022-11-12T20:02:57.180316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the Model and Making Predictions\nrfg_pipeline.fit(X_train, y_train)\nprint('Training Done!')\nrfg_predictions = rfg_pipeline.predict(X_valid)\nprint('Predictions Done!')","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:02:57.398474Z","iopub.execute_input":"2022-11-12T20:02:57.399216Z","iopub.status.idle":"2022-11-12T20:03:00.644970Z","shell.execute_reply.started":"2022-11-12T20:02:57.399182Z","shell.execute_reply":"2022-11-12T20:03:00.643766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RMSE\nrfg_rmse = rmse(rfg_predictions, y_valid)\nprint('Random Forest Regressor RMSE: ', rfg_rmse)","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:03:00.646676Z","iopub.execute_input":"2022-11-12T20:03:00.646973Z","iopub.status.idle":"2022-11-12T20:03:00.652530Z","shell.execute_reply.started":"2022-11-12T20:03:00.646945Z","shell.execute_reply":"2022-11-12T20:03:00.651537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and Validation Scores\nprint('Train Score: %.2f%%' % (rfg_pipeline.score(X_train, y_train) * 100))\nprint('Validation Score: %.2f%%' % (rfg_pipeline.score(X_valid, y_valid) * 100))","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:03:00.653889Z","iopub.execute_input":"2022-11-12T20:03:00.654288Z","iopub.status.idle":"2022-11-12T20:03:00.909485Z","shell.execute_reply.started":"2022-11-12T20:03:00.654251Z","shell.execute_reply":"2022-11-12T20:03:00.908633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-----\n\n<b>XGBoost</b>","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:03:00.911346Z","iopub.execute_input":"2022-11-12T20:03:00.911680Z","iopub.status.idle":"2022-11-12T20:03:00.915945Z","shell.execute_reply.started":"2022-11-12T20:03:00.911638Z","shell.execute_reply":"2022-11-12T20:03:00.914977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the Model\nxgb_model = XGBRegressor(\n    n_estimators=500\n    , learning_rate=0.05\n    , n_jobs=4\n)\n\nxgb_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor)\n])","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:03:00.917401Z","iopub.execute_input":"2022-11-12T20:03:00.917767Z","iopub.status.idle":"2022-11-12T20:03:00.926523Z","shell.execute_reply.started":"2022-11-12T20:03:00.917730Z","shell.execute_reply":"2022-11-12T20:03:00.925795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the Model and Making Predictions\n\nxgb_X_train = xgb_pipeline.fit_transform(X_train)\nxgb_X_valid = xgb_pipeline.transform(X_valid)\n\nxgb_model.fit(\n    xgb_X_train, y_train\n    , early_stopping_rounds=5\n    , eval_set=[(xgb_X_valid, y_valid)]\n    , verbose=False\n)\n\nprint('Training Done!')\n\nxgb_predictions = xgb_model.predict(xgb_X_valid)\nprint('Prediction Done!')","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:03:00.927523Z","iopub.execute_input":"2022-11-12T20:03:00.928272Z","iopub.status.idle":"2022-11-12T20:03:02.169709Z","shell.execute_reply.started":"2022-11-12T20:03:00.928244Z","shell.execute_reply":"2022-11-12T20:03:02.168855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RMSE\nxgb_rmse = rmse(xgb_predictions, y_valid)\nprint('XGBoost Regressor RMSE: ', xgb_rmse)","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:03:02.173003Z","iopub.execute_input":"2022-11-12T20:03:02.175038Z","iopub.status.idle":"2022-11-12T20:03:02.182820Z","shell.execute_reply.started":"2022-11-12T20:03:02.175003Z","shell.execute_reply":"2022-11-12T20:03:02.182060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and Validation Scores\nprint('Train Score: %.2f%%' % (xgb_model.score(xgb_X_train, y_train) * 100))\nprint('Validation Score: %.2f%%' % (xgb_model.score(xgb_X_valid, y_valid) * 100))","metadata":{"execution":{"iopub.status.busy":"2022-11-12T20:03:02.183850Z","iopub.execute_input":"2022-11-12T20:03:02.184119Z","iopub.status.idle":"2022-11-12T20:03:02.210500Z","shell.execute_reply.started":"2022-11-12T20:03:02.184094Z","shell.execute_reply":"2022-11-12T20:03:02.209829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analysing the threee models, we got impressive results here:\n\n> RMSE lower than 15 dollars;\n\n> Scores higher than 99%;\n\n> Also, we can discar **overfitting** assumption since the gap between train and validation scores are not big and becausee we avoided **Target Leakage** dropping **Margin** and **Profit** Features at the beggining of the analysis.","metadata":{}},{"cell_type":"markdown","source":"----\n\n<h1>ü•í Saving and Loading the Model</h1>","metadata":{}},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2022-11-12T19:37:19.865135Z","iopub.execute_input":"2022-11-12T19:37:19.865641Z","iopub.status.idle":"2022-11-12T19:37:19.869210Z","shell.execute_reply.started":"2022-11-12T19:37:19.865613Z","shell.execute_reply":"2022-11-12T19:37:19.868364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the Model\n#pickle.dump(rfg_model, open('rfg_model.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-11-12T00:37:37.631202Z","iopub.execute_input":"2022-11-12T00:37:37.631699Z","iopub.status.idle":"2022-11-12T00:37:37.636677Z","shell.execute_reply.started":"2022-11-12T00:37:37.631636Z","shell.execute_reply":"2022-11-12T00:37:37.635242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the Model\n#pickled_model = pickle.load(open('rfg_modedl.pkl', 'rb'))\n#pickled_model.predict(test)","metadata":{"execution":{"iopub.status.busy":"2022-11-12T00:37:43.464972Z","iopub.execute_input":"2022-11-12T00:37:43.465369Z","iopub.status.idle":"2022-11-12T00:37:43.470977Z","shell.execute_reply.started":"2022-11-12T00:37:43.465329Z","shell.execute_reply":"2022-11-12T00:37:43.469641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----\n\nHoorray!!! This is one more finished tutorial! See you next time üëãüëã\n\n----\n\n<br/>\n<h1>üì´ Reach Me üì´</h1>\n<br/>\n\n> **Email:** **[csfelix08@gmail.com](mailto:csfelix08@gmail.com?)**\n\n> **Linkedin:** **[linkedin.com/in/csfelix/](https://www.linkedin.com/in/csfelix/)**\n\n> **Instagram:** **[instagram.com/c0deplus/](https://www.instagram.com/c0deplus/)**\n\n> **Portfolio:** **[CSFelix.io](https://csfelix.github.io/)**\n\n> **Kaggle:** **[DSFelix](https://www.kaggle.com/dsfelix)**","metadata":{}}]}